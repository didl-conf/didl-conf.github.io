<!doctype html>

<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DIDL 2021 - Fifth Workshop on Distributed Infrastructures for Deep Learning</title>
  <meta name="description" content="Distributed Deep Learning">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>

  <!-- Latest compiled and minified CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u"
    crossorigin="anonymous">

  <!-- Optional theme -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp"
    crossorigin="anonymous">

  <!-- Latest compiled and minified JavaScript -->
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa"
    crossorigin="anonymous"></script>

   <link href="blog.css" rel="stylesheet">

   <!--
  <style>
	table, th, td { border: 1px solid black; }
  </style>
  -->

</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-16788810-5', 'auto');
  ga('send', 'pageview');

</script>

<body>

      <div class="container" style="max-width:900px  !important;">
        <div style="max-width:940px  !important;">
          <p align='center'>
    <a href="http://2021.middleware-conference.org/"><img src="header.jpg" align='center' style="width:700px; height:auto"></img></a>
  </p>
      </div>
    </div>


    <div class="container" style="max-width:900px  !important;">

      <div class="blog-header">
        <h1 class="blog-title">Fifth Workshop on Distributed Infrastructures for Deep Learning (DIDL) 2021</h1>
        <p class="lead blog-description"><!--<a href="http://2021.middleware-conference.org/index.php/workshops/">-->Middleware 2021 Workshops<!--</a>--></p>
        <p class="blog-description"> </p>
      </div>

      <div class="row">
        <div class="col-sm-12 blog-main">
     <div class="blog-post">

<p align="justify">
The DIDL workshop is co-located with <a href="http://2021.middleware-conference.org">ACM/IFIP Middleware 2021</a>, which takes place from December 6-10 in Qu√©bec, Canada.

<p align="justify">
Deep learning is a rapidly growing field of machine learning, and has proven successful in many domains, including computer vision, language translation, and speech recognition. The training of deep neural networks is resource intensive, requiring compute accelerators such as GPUs, as well as large amounts of storage and memory, and network bandwidth. Additionally, getting the training data ready requires a lot of tooling for data cleansing, data merging, ambiguity resolution, etc. Sophisticated middleware abstractions are needed to schedule resources, manage the distributed training job as well as visualize how well the training is progressing. Likewise, serving the large neural network models with low latency constraints can require middleware to manage model caching, selection, and refinement.

<p align="justify">
All the major cloud providers, including Amazon, Google, IBM, and  Microsoft have started to offer cloud services recently to train and/or serve deep neural network models. In addition, there is a lot of activity in open source middleware for deep learning, including but not limited to Tensorflow, Theano, Caffe2, PyTorch, MXNet, Hugging Face, and fairseq. There are also efforts to extend existing platforms such as Spark and Ray for various aspects of deep learning.

<p align="justify">
This workshop focuses on the tools, frameworks, and algorithms to support executing deep learning algorithms in a distributed environment. As new hardware and accelerators become available, the middleware and systems need to be able exploit their capabilities and ensure they are utilized efficiently.

<p align="justify">
  <!-- The workshop is scheduled to be in the <b>morning on Dec 7, 2021</b>. -->

<h2 id="agenda">Workshop Agenda (Tentative) </h2>

<p><strong>Introduction (11:00 - 11:10 EST)</strong></br>

<p><strong>Keynote: AI/ML Pipelines using CodeFlare (11:10 - 12:10 EST)</strong></br>
  Mudhakar Srivatsa, IBM Research
  <p> 
    <p><strong>Abstract:</strong> Pipelines have become a ubiquitous construct in machine learning spanning tasks ranging from data cleaning and preprocessing, training foundational models, model optimization and transfer learning and low latency inferencing.  While the many pipeline construct has existed for many years (e.g., SciKit learn pipelines, Spark pipelines), this talk will focus on a process calculus style definition of pipeline - called CodeFlare pipelines - that makes it readily amenable to scaling complex AI/ML workflows on a commodity cluster. CodeFlare pipelines not only enable data scientists to introduce compute, data and multi-stage parallelism using simple annotations on the pipeline graph, but also operationalize them on a hybrid cloud platform (Red Hat OpenShift), thereby making the solution  deployable just about anywhere and leverage the benefits of serverless computing. This talk will cover a basic realization of CodeFlare pipelines on the Ray platform (1.7.0 release) that has shown near linear scalability.

<p><strong>Bio:</strong>
Mudhakar Srivatsa is a distinguished research staff member at the Distributed AI department in IBM T. J. Watson Research Center. His work is focussed on cloud-native scaling of AI/ML workloads with applications to large scale spatial and timeseries data. He has led the deployment of AI-assisted solutions for air traffic control, IT operations, combating piracy in the maritime domain, and public safety in dense urban environments such as stadiums and music festivals.
<p>

<p><strong>Break (12:10 - 12:30 EST)</strong></br>

<p><strong>Tutorial: Use of Codeflare and Ray for Deep Learning Tasks (12:30 - 1:00 EST)</strong></br>
  Linsong Chu, IBM Research
<p>
  <p><strong>Abstract:</strong> Benchmarking is crucial for natural language understanding systems, but also very challenging. A variety of collections of resources are needed for training, evaluating and analyzing the system, which requires a large scale distributed deep learning system. In this talk, Linsong will show how Ray, and Ray's integration with Horovod, can be used to train and evaluate deep learning models at scale for tasks like NLP benchmarking. Linsong will demonstrate this workflow on two sample applications, GLUE Benchmarking using Ray and Anomaly Detection with Remote Sensing data using Ray+Horovod Integration.

  <p><strong>Bio:</strong>  
  Linsong Chu is a Research Engineer in IBM Research with specialization on large scale machine learning and spatiotemporal analysis.

  <p><strong>Paper presentations (1:00 - 1:40 EST)</strong></br>

  <p><i><a href=""></a>RAMPS: Next Generation Platform for Real Time and Resilient IoT Analytics using MmWave and Programmable Switches</i></br>
    Vishal Shrivastav (Purdue University), Dimitrios Koutsonikolas (Northeastern University), Saurabh Bagchi (Purdue University)</br>

  <p><i><a href=""></a>Reproducible Model Sharing for AI Practitioners</a></i></br>
  Amin Moradi (Leiden University), Alexandru Uta (Leiden University)

  <p><strong>Workshop conclusion (1:40 - 1:45 EST)</strong></br>

<h2>
    Workshop call for papers
  </h2>
  <p><a href="cfp.html">Call For Papers (CFP)</a></p>

  <h2>
    Workshop Co-chairs
  </h2>

  <p>
    Bishwaranjan Bhattacharjee, IBM Research<br/>
    Vatche Ishakian, IBM Research<br/>
    Vinod Muthusamy, IBM Research<br/>
  </p>

  <h2>
    Program Committee (Tentative)
  </h2>

  <p>
    Parag Chandakkar, Walmart Labs <br/>
    Ian Foster, Argonne National Laboratory and the University of Chicago <br/>
    Matthew Hill, Dataminr <br/>
    Mayoore Jaiswal, Nvidia <br/>
    Gauri Joshi, Carnegie Mellon University<br/>
    Jayaram K. R., IBM Research<br/>
    Ruben Mayer, Technical University of Munich<br/>
    Pietro Michiardi, Eurecom<br/>
    Phuong Nguyen, eBay <br/>
    Peter Pietzuch, Imperial College<br/>
    Chuan Wu, University of Hong Kong<br/>
  </p>


         <p>
    &nbsp;
  </p>
         <p>
    &nbsp;
  </p>



          </div><!-- /.blog-post -->
      </div><!-- /.row -->

    </div><!-- /.container -->

</body>

</html>
